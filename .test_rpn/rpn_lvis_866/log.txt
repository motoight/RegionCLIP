[09/09 19:06:08] detectron2 INFO: Rank of current process: 0. World size: 1
[09/09 19:06:11] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
numpy                   1.23.2
detectron2              RegionCLIP @/home/wulei04/ovr/RegionCLIP/detectron2
Compiler                GCC 7.5
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.8.2+cu111 @/home/wulei04/miniconda3/envs/detic/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               None - invalid!
Pillow                  9.2.0
torchvision             0.9.2+cu111 @/home/wulei04/miniconda3/envs/detic/lib/python3.8/site-packages/torchvision
torchvision arch flags  /home/wulei04/miniconda3/envs/detic/lib/python3.8/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20220512
iopath                  0.1.8
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/09 19:06:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_zsinf.yaml', dist_url='tcp://127.0.0.1:59402', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './pretrained_ckpt/regionclip/regionclip_pretrained-cc_rn50.pth', 'MODEL.CLIP.TEXT_EMB_PATH', './pretrained_ckpt/concept_emb/coco_65_cls_emb.pth', 'MODEL.CLIP.CROP_REGION_TYPE', 'RPN', 'MODEL.CLIP.MULTIPLY_RPN_SCORE', 'True', 'MODEL.CLIP.OFFLINE_RPN_CONFIG', './configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'MODEL.CLIP.BB_RPN_WEIGHTS', './pretrained_ckpt/rpn/rpn_lvis_866.pth', 'OUTPUT_DIR', '.test_rpn/rpn_lvis_866'], resume=False)
[09/09 19:06:11] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_zsinf.yaml:
_BASE_: "./CLIP_fast_rcnn_R_50_C4_ovd.yaml"
MODEL:
  ROI_HEADS:
    NUM_CLASSES: 65
    NMS_THRESH_TEST: 0.5
  CLIP:
    NO_BOX_DELTA: True
    OFFLINE_RPN_NMS_THRESH: 0.9
[09/09 19:06:11] detectron2 INFO: Running with full config:
AUG:
  COLOR_JITTER:
  - 0.4
  - 0.4
  - 0.4
  - 0.1
  - 0.0
  DROPBLOCK_BLOCK_SIZE: 7
  DROPBLOCK_KEEP_PROB: 1.0
  DROPBLOCK_LAYERS:
  - 3
  - 4
  GAUSSIAN_BLUR: 0.0
  GRAY_SCALE: 0.0
  INTERPOLATION: 3
  MIXCUT: 0.0
  MIXCUT_AND_MIXUP: false
  MIXCUT_MINMAX: []
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 0.0
  MIXUP_SWITCH_PROB: 0.5
  RATIO:
  - 0.75
  - 1.3333333333333333
  SCALE:
  - 0.08
  - 1.0
  TEST:
    CENTER_CROP: false
    IMAGE_SIZE:
    - 224
    - 224
    INTERPOLATION: 3
    MAX_SIZE: null
  TIMM_AUG:
    USE_LOADER: false
    USE_TRANSFORM: false
  TRAIN:
    IMAGE_SIZE:
    - 224
    - 224
    MAX_SIZE: null
  USE_TIMM: false
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ATTR_LABELMAP_FILE: ''
  AUX: []
  BOX_EXTRA_FIELDS: []
  FACTORY_AUX: []
  FACTORY_TEST: []
  FACTORY_TRAIN: []
  FILTERED_CLASSIFICATION_DATASETS: ''
  HIERARCHY_FILE: ''
  LABELMAP_FILE: ''
  MAX_SEQ_LENGTH: 35
  NUM_CLASSES: 0
  PATH_AUX: []
  PATH_TEST: []
  PATH_TRAIN: []
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  ROOT: ''
  TEST:
  - coco_2017_ovd_all_test
  TEST_SET: val
  TRAIN:
  - coco_2017_ovd_b_train
  TRAIN_SET: train
  VAL_SET: ''
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  TEXT_TOKENIZER: openai_bpe
INPUT_DIR: ./datasets/custom_images
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_clip_resnet_backbone
  CLIP:
    BB_RPN_WEIGHTS: ./pretrained_ckpt/rpn/rpn_lvis_866.pth
    BG_CLS_LOSS_WEIGHT: 0.2
    CLSS_TEMP: 0.01
    CONCEPT_POOL_EMB: null
    CONCEPT_THRES: null
    CROP_REGION_TYPE: RPN
    FOCAL_SCALED_LOSS: 0.5
    GATHER_GPUS: false
    GET_CONCEPT_EMB: false
    GRID_REGIONS: false
    IMS_PER_BATCH_TEST: 8
    MULTIPLY_RPN_SCORE: true
    NO_BOX_DELTA: true
    OFFLINE_RPN_CONFIG: ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    OFFLINE_RPN_LSJ_PRETRAINED: false
    OFFLINE_RPN_NMS_THRESH: 0.9
    OFFLINE_RPN_POST_NMS_TOPK_TEST: null
    ONLY_SAMPLE_FG_PROPOSALS: false
    OPENSET_TEST_NUM_CLASSES: null
    OPENSET_TEST_TEXT_EMB_PATH: null
    PRETRAIN_IMG_TXT_LEVEL: true
    PRETRAIN_ONLY_EOT: false
    PRETRAIN_RPN_REGIONS: null
    PRETRAIN_SAMPLE_REGIONS: null
    RUN_CVPR_OVR: false
    TEACHER_CONCEPT_POOL_EMB: null
    TEACHER_POOLER_RESOLUTION: 14
    TEACHER_RESNETS_DEPTH: 50
    TEXT_EMB_DIM: 1024
    TEXT_EMB_PATH: ./pretrained_ckpt/concept_emb/coco_65_cls_emb.pth
    USE_TEXT_EMB_CLASSIFIER: true
    VIS: false
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: CLIPFastRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 0.48145466
  - 0.4578275
  - 0.40821073
  PIXEL_STD:
  - 0.26862954
  - 0.26130258
  - 0.27577711
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: true
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: CLIPRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 65
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.001
    SOFT_NMS_ENABLED: false
    SOFT_NMS_METHOD: gaussian
    SOFT_NMS_PRUNE: 0.001
    SOFT_NMS_SIGMA: 0.5
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pretrained_ckpt/regionclip/regionclip_pretrained-cc_rn50.pth
OUTPUT_DIR: .test_rpn/rpn_lvis_866
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 60000
  - 80000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 5000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 25000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[09/09 19:06:11] detectron2 INFO: Full config saved to .test_rpn/rpn_lvis_866/config.yaml
[09/09 19:06:11] d2.utils.env INFO: Using a generated random seed 11743367
[09/09 19:06:37] d2.engine.defaults INFO: Model:
CLIPFastRCNN(
  (offline_backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (backbone): ModifiedResNet(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)
    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): FrozenBatchNorm2d(num_features=32, eps=1e-05)
    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn3): FrozenBatchNorm2d(num_features=64, eps=1e-05)
    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (relu): ReLU(inplace=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        (avgpool): Identity()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (attnpool): AttentionPool2d(
      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
    )
  )
  (offline_proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): CLIPRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=65, bias=False)
      (cls_bg_score): Linear(in_features=1024, out_features=1, bias=False)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[09/09 19:06:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pretrained_ckpt/regionclip/regionclip_pretrained-cc_rn50.pth ...
[09/09 19:06:46] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (256, 256, 3, 3) in the checkpoint but (1024, 1024, 3, 3) in the model! You might want to double check if this is expected.
[09/09 19:06:46] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (256,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/09 19:06:46] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (15, 1024, 1, 1) in the model! You might want to double check if this is expected.
[09/09 19:06:46] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.
[09/09 19:06:46] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (60, 1024, 1, 1) in the model! You might want to double check if this is expected.
[09/09 19:06:46] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.
[09/09 19:06:46] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34moffline_backbone.res2.0.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res2.0.conv1.weight[0m
[34moffline_backbone.res2.0.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res2.0.conv2.weight[0m
[34moffline_backbone.res2.0.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res2.0.conv3.weight[0m
[34moffline_backbone.res2.0.shortcut.norm.{bias, weight}[0m
[34moffline_backbone.res2.0.shortcut.weight[0m
[34moffline_backbone.res2.1.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res2.1.conv1.weight[0m
[34moffline_backbone.res2.1.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res2.1.conv2.weight[0m
[34moffline_backbone.res2.1.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res2.1.conv3.weight[0m
[34moffline_backbone.res2.2.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res2.2.conv1.weight[0m
[34moffline_backbone.res2.2.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res2.2.conv2.weight[0m
[34moffline_backbone.res2.2.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res2.2.conv3.weight[0m
[34moffline_backbone.res3.0.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res3.0.conv1.weight[0m
[34moffline_backbone.res3.0.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res3.0.conv2.weight[0m
[34moffline_backbone.res3.0.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res3.0.conv3.weight[0m
[34moffline_backbone.res3.0.shortcut.norm.{bias, weight}[0m
[34moffline_backbone.res3.0.shortcut.weight[0m
[34moffline_backbone.res3.1.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res3.1.conv1.weight[0m
[34moffline_backbone.res3.1.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res3.1.conv2.weight[0m
[34moffline_backbone.res3.1.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res3.1.conv3.weight[0m
[34moffline_backbone.res3.2.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res3.2.conv1.weight[0m
[34moffline_backbone.res3.2.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res3.2.conv2.weight[0m
[34moffline_backbone.res3.2.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res3.2.conv3.weight[0m
[34moffline_backbone.res3.3.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res3.3.conv1.weight[0m
[34moffline_backbone.res3.3.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res3.3.conv2.weight[0m
[34moffline_backbone.res3.3.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res3.3.conv3.weight[0m
[34moffline_backbone.res4.0.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res4.0.conv1.weight[0m
[34moffline_backbone.res4.0.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res4.0.conv2.weight[0m
[34moffline_backbone.res4.0.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res4.0.conv3.weight[0m
[34moffline_backbone.res4.0.shortcut.norm.{bias, weight}[0m
[34moffline_backbone.res4.0.shortcut.weight[0m
[34moffline_backbone.res4.1.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res4.1.conv1.weight[0m
[34moffline_backbone.res4.1.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res4.1.conv2.weight[0m
[34moffline_backbone.res4.1.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res4.1.conv3.weight[0m
[34moffline_backbone.res4.2.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res4.2.conv1.weight[0m
[34moffline_backbone.res4.2.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res4.2.conv2.weight[0m
[34moffline_backbone.res4.2.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res4.2.conv3.weight[0m
[34moffline_backbone.res4.3.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res4.3.conv1.weight[0m
[34moffline_backbone.res4.3.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res4.3.conv2.weight[0m
[34moffline_backbone.res4.3.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res4.3.conv3.weight[0m
[34moffline_backbone.res4.4.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res4.4.conv1.weight[0m
[34moffline_backbone.res4.4.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res4.4.conv2.weight[0m
[34moffline_backbone.res4.4.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res4.4.conv3.weight[0m
[34moffline_backbone.res4.5.conv1.norm.{bias, weight}[0m
[34moffline_backbone.res4.5.conv1.weight[0m
[34moffline_backbone.res4.5.conv2.norm.{bias, weight}[0m
[34moffline_backbone.res4.5.conv2.weight[0m
[34moffline_backbone.res4.5.conv3.norm.{bias, weight}[0m
[34moffline_backbone.res4.5.conv3.weight[0m
[34moffline_backbone.stem.conv1.norm.{bias, weight}[0m
[34moffline_backbone.stem.conv1.weight[0m
[34moffline_proposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34moffline_proposal_generator.rpn_head.conv.{bias, weight}[0m
[34moffline_proposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_bg_score.weight[0m
[34mroi_heads.box_predictor.cls_score.weight[0m
[09/09 19:06:46] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mlang_encoder.{positional_embedding, text_projection}[0m
  [35mlang_encoder.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.0.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.0.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.1.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.1.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.2.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.2.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.3.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.3.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.4.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.4.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.5.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.5.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.6.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.6.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.7.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.7.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.8.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.8.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.9.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.9.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.10.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.10.ln_2.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
  [35mlang_encoder.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.11.ln_1.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
  [35mlang_encoder.transformer.resblocks.11.ln_2.{bias, weight}[0m
  [35mlang_encoder.token_embedding.weight[0m
  [35mlang_encoder.ln_final.{bias, weight}[0m
  [35mteacher_backbone.conv1.weight[0m
  [35mteacher_backbone.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.conv2.weight[0m
  [35mteacher_backbone.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.conv3.weight[0m
  [35mteacher_backbone.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.0.conv1.weight[0m
  [35mteacher_backbone.layer1.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.0.conv2.weight[0m
  [35mteacher_backbone.layer1.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.0.conv3.weight[0m
  [35mteacher_backbone.layer1.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.0.downsample.0.weight[0m
  [35mteacher_backbone.layer1.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.1.conv1.weight[0m
  [35mteacher_backbone.layer1.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.1.conv2.weight[0m
  [35mteacher_backbone.layer1.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.1.conv3.weight[0m
  [35mteacher_backbone.layer1.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.2.conv1.weight[0m
  [35mteacher_backbone.layer1.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.2.conv2.weight[0m
  [35mteacher_backbone.layer1.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer1.2.conv3.weight[0m
  [35mteacher_backbone.layer1.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.0.conv1.weight[0m
  [35mteacher_backbone.layer2.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.0.conv2.weight[0m
  [35mteacher_backbone.layer2.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.0.conv3.weight[0m
  [35mteacher_backbone.layer2.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.0.downsample.0.weight[0m
  [35mteacher_backbone.layer2.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.1.conv1.weight[0m
  [35mteacher_backbone.layer2.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.1.conv2.weight[0m
  [35mteacher_backbone.layer2.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.1.conv3.weight[0m
  [35mteacher_backbone.layer2.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.2.conv1.weight[0m
  [35mteacher_backbone.layer2.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.2.conv2.weight[0m
  [35mteacher_backbone.layer2.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.2.conv3.weight[0m
  [35mteacher_backbone.layer2.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.3.conv1.weight[0m
  [35mteacher_backbone.layer2.3.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.3.conv2.weight[0m
  [35mteacher_backbone.layer2.3.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer2.3.conv3.weight[0m
  [35mteacher_backbone.layer2.3.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.0.conv1.weight[0m
  [35mteacher_backbone.layer3.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.0.conv2.weight[0m
  [35mteacher_backbone.layer3.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.0.conv3.weight[0m
  [35mteacher_backbone.layer3.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.0.downsample.0.weight[0m
  [35mteacher_backbone.layer3.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.1.conv1.weight[0m
  [35mteacher_backbone.layer3.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.1.conv2.weight[0m
  [35mteacher_backbone.layer3.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.1.conv3.weight[0m
  [35mteacher_backbone.layer3.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.2.conv1.weight[0m
  [35mteacher_backbone.layer3.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.2.conv2.weight[0m
  [35mteacher_backbone.layer3.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.2.conv3.weight[0m
  [35mteacher_backbone.layer3.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.3.conv1.weight[0m
  [35mteacher_backbone.layer3.3.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.3.conv2.weight[0m
  [35mteacher_backbone.layer3.3.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.3.conv3.weight[0m
  [35mteacher_backbone.layer3.3.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.4.conv1.weight[0m
  [35mteacher_backbone.layer3.4.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.4.conv2.weight[0m
  [35mteacher_backbone.layer3.4.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.4.conv3.weight[0m
  [35mteacher_backbone.layer3.4.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.5.conv1.weight[0m
  [35mteacher_backbone.layer3.5.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.5.conv2.weight[0m
  [35mteacher_backbone.layer3.5.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer3.5.conv3.weight[0m
  [35mteacher_backbone.layer3.5.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.0.conv1.weight[0m
  [35mteacher_backbone.layer4.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.0.conv2.weight[0m
  [35mteacher_backbone.layer4.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.0.conv3.weight[0m
  [35mteacher_backbone.layer4.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.0.downsample.0.weight[0m
  [35mteacher_backbone.layer4.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.1.conv1.weight[0m
  [35mteacher_backbone.layer4.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.1.conv2.weight[0m
  [35mteacher_backbone.layer4.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.1.conv3.weight[0m
  [35mteacher_backbone.layer4.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.2.conv1.weight[0m
  [35mteacher_backbone.layer4.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.2.conv2.weight[0m
  [35mteacher_backbone.layer4.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.layer4.2.conv3.weight[0m
  [35mteacher_backbone.layer4.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mteacher_backbone.attnpool.positional_embedding[0m
  [35mteacher_backbone.attnpool.k_proj.{bias, weight}[0m
  [35mteacher_backbone.attnpool.q_proj.{bias, weight}[0m
  [35mteacher_backbone.attnpool.v_proj.{bias, weight}[0m
  [35mteacher_backbone.attnpool.c_proj.{bias, weight}[0m
  [35moffline_backbone.fpn_lateral2.{bias, weight}[0m
  [35moffline_backbone.fpn_output2.{bias, weight}[0m
  [35moffline_backbone.fpn_lateral3.{bias, weight}[0m
  [35moffline_backbone.fpn_output3.{bias, weight}[0m
  [35moffline_backbone.fpn_lateral4.{bias, weight}[0m
  [35moffline_backbone.fpn_output4.{bias, weight}[0m
  [35moffline_backbone.fpn_lateral5.{bias, weight}[0m
  [35moffline_backbone.fpn_output5.{bias, weight}[0m
  [35moffline_backbone.bottom_up.stem.conv1.weight[0m
  [35moffline_backbone.bottom_up.stem.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res2.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res2.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res2.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res2.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res2.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res2.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res2.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res2.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.res2.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.3.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.3.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.3.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.3.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.3.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.3.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.3.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.3.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.3.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.3.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.3.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.3.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.4.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.4.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.4.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.4.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.4.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.4.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.5.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.5.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.5.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.5.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.5.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.5.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res5.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res5.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res5.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res5.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res5.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res5.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res5.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res5.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.res5.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
[09/09 19:06:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pretrained_ckpt/rpn/rpn_lvis_866.pth ...
[09/09 19:06:46] d2.checkpoint.clip_model_loading INFO: Renaming CLIP weights ......
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: Shape of offline_proposal_generator.rpn_head.anchor_deltas.bias in checkpoint is torch.Size([12]), while shape of offline_proposal_generator.rpn_head.anchor_deltas.bias in model is torch.Size([60]).
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: offline_proposal_generator.rpn_head.anchor_deltas.bias will not be loaded. Please double check and see if this is desired.
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: Shape of offline_proposal_generator.rpn_head.anchor_deltas.weight in checkpoint is torch.Size([12, 256, 1, 1]), while shape of offline_proposal_generator.rpn_head.anchor_deltas.weight in model is torch.Size([60, 1024, 1, 1]).
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: offline_proposal_generator.rpn_head.anchor_deltas.weight will not be loaded. Please double check and see if this is desired.
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: Shape of offline_proposal_generator.rpn_head.conv.bias in checkpoint is torch.Size([256]), while shape of offline_proposal_generator.rpn_head.conv.bias in model is torch.Size([1024]).
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: offline_proposal_generator.rpn_head.conv.bias will not be loaded. Please double check and see if this is desired.
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: Shape of offline_proposal_generator.rpn_head.conv.weight in checkpoint is torch.Size([256, 256, 3, 3]), while shape of offline_proposal_generator.rpn_head.conv.weight in model is torch.Size([1024, 1024, 3, 3]).
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: offline_proposal_generator.rpn_head.conv.weight will not be loaded. Please double check and see if this is desired.
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: Shape of offline_proposal_generator.rpn_head.objectness_logits.bias in checkpoint is torch.Size([3]), while shape of offline_proposal_generator.rpn_head.objectness_logits.bias in model is torch.Size([15]).
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: offline_proposal_generator.rpn_head.objectness_logits.bias will not be loaded. Please double check and see if this is desired.
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: Shape of offline_proposal_generator.rpn_head.objectness_logits.weight in checkpoint is torch.Size([3, 256, 1, 1]), while shape of offline_proposal_generator.rpn_head.objectness_logits.weight in model is torch.Size([15, 1024, 1, 1]).
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: offline_proposal_generator.rpn_head.objectness_logits.weight will not be loaded. Please double check and see if this is desired.
[09/09 19:06:47] d2.checkpoint.clip_model_loading WARNING: No weights in checkpoint matched with model.
[09/09 19:06:47] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.
[09/09 19:06:47] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (60, 1024, 1, 1) in the model! You might want to double check if this is expected.
[09/09 19:06:47] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (256,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/09 19:06:47] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (256, 256, 3, 3) in the checkpoint but (1024, 1024, 3, 3) in the model! You might want to double check if this is expected.
[09/09 19:06:47] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.
[09/09 19:06:47] fvcore.common.checkpoint WARNING: Skip loading parameter 'offline_proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (15, 1024, 1, 1) in the model! You might want to double check if this is expected.
[09/09 19:06:47] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.attnpool.c_proj.{bias, weight}[0m
[34mbackbone.attnpool.k_proj.{bias, weight}[0m
[34mbackbone.attnpool.positional_embedding[0m
[34mbackbone.attnpool.q_proj.{bias, weight}[0m
[34mbackbone.attnpool.v_proj.{bias, weight}[0m
[34mbackbone.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.conv1.weight[0m
[34mbackbone.conv2.weight[0m
[34mbackbone.conv3.weight[0m
[34mbackbone.layer1.0.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.0.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.0.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.0.conv1.weight[0m
[34mbackbone.layer1.0.conv2.weight[0m
[34mbackbone.layer1.0.conv3.weight[0m
[34mbackbone.layer1.0.downsample.0.weight[0m
[34mbackbone.layer1.0.downsample.1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.1.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.1.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.1.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.1.conv1.weight[0m
[34mbackbone.layer1.1.conv2.weight[0m
[34mbackbone.layer1.1.conv3.weight[0m
[34mbackbone.layer1.2.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.2.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.2.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer1.2.conv1.weight[0m
[34mbackbone.layer1.2.conv2.weight[0m
[34mbackbone.layer1.2.conv3.weight[0m
[34mbackbone.layer2.0.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.0.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.0.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.0.conv1.weight[0m
[34mbackbone.layer2.0.conv2.weight[0m
[34mbackbone.layer2.0.conv3.weight[0m
[34mbackbone.layer2.0.downsample.0.weight[0m
[34mbackbone.layer2.0.downsample.1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.1.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.1.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.1.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.1.conv1.weight[0m
[34mbackbone.layer2.1.conv2.weight[0m
[34mbackbone.layer2.1.conv3.weight[0m
[34mbackbone.layer2.2.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.2.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.2.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.2.conv1.weight[0m
[34mbackbone.layer2.2.conv2.weight[0m
[34mbackbone.layer2.2.conv3.weight[0m
[34mbackbone.layer2.3.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.3.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.3.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer2.3.conv1.weight[0m
[34mbackbone.layer2.3.conv2.weight[0m
[34mbackbone.layer2.3.conv3.weight[0m
[34mbackbone.layer3.0.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.0.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.0.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.0.conv1.weight[0m
[34mbackbone.layer3.0.conv2.weight[0m
[34mbackbone.layer3.0.conv3.weight[0m
[34mbackbone.layer3.0.downsample.0.weight[0m
[34mbackbone.layer3.0.downsample.1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.1.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.1.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.1.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.1.conv1.weight[0m
[34mbackbone.layer3.1.conv2.weight[0m
[34mbackbone.layer3.1.conv3.weight[0m
[34mbackbone.layer3.2.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.2.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.2.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.2.conv1.weight[0m
[34mbackbone.layer3.2.conv2.weight[0m
[34mbackbone.layer3.2.conv3.weight[0m
[34mbackbone.layer3.3.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.3.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.3.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.3.conv1.weight[0m
[34mbackbone.layer3.3.conv2.weight[0m
[34mbackbone.layer3.3.conv3.weight[0m
[34mbackbone.layer3.4.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.4.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.4.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.4.conv1.weight[0m
[34mbackbone.layer3.4.conv2.weight[0m
[34mbackbone.layer3.4.conv3.weight[0m
[34mbackbone.layer3.5.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.5.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.5.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer3.5.conv1.weight[0m
[34mbackbone.layer3.5.conv2.weight[0m
[34mbackbone.layer3.5.conv3.weight[0m
[34mbackbone.layer4.0.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.0.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.0.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.0.conv1.weight[0m
[34mbackbone.layer4.0.conv2.weight[0m
[34mbackbone.layer4.0.conv3.weight[0m
[34mbackbone.layer4.0.downsample.0.weight[0m
[34mbackbone.layer4.0.downsample.1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.1.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.1.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.1.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.1.conv1.weight[0m
[34mbackbone.layer4.1.conv2.weight[0m
[34mbackbone.layer4.1.conv3.weight[0m
[34mbackbone.layer4.2.bn1.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.2.bn2.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.2.bn3.{bias, running_mean, running_var, weight}[0m
[34mbackbone.layer4.2.conv1.weight[0m
[34mbackbone.layer4.2.conv2.weight[0m
[34mbackbone.layer4.2.conv3.weight[0m
[34moffline_backbone.res2.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.0.conv1.weight[0m
[34moffline_backbone.res2.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.0.conv2.weight[0m
[34moffline_backbone.res2.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.0.conv3.weight[0m
[34moffline_backbone.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.0.shortcut.weight[0m
[34moffline_backbone.res2.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.1.conv1.weight[0m
[34moffline_backbone.res2.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.1.conv2.weight[0m
[34moffline_backbone.res2.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.1.conv3.weight[0m
[34moffline_backbone.res2.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.2.conv1.weight[0m
[34moffline_backbone.res2.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.2.conv2.weight[0m
[34moffline_backbone.res2.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res2.2.conv3.weight[0m
[34moffline_backbone.res3.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.0.conv1.weight[0m
[34moffline_backbone.res3.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.0.conv2.weight[0m
[34moffline_backbone.res3.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.0.conv3.weight[0m
[34moffline_backbone.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.0.shortcut.weight[0m
[34moffline_backbone.res3.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.1.conv1.weight[0m
[34moffline_backbone.res3.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.1.conv2.weight[0m
[34moffline_backbone.res3.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.1.conv3.weight[0m
[34moffline_backbone.res3.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.2.conv1.weight[0m
[34moffline_backbone.res3.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.2.conv2.weight[0m
[34moffline_backbone.res3.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.2.conv3.weight[0m
[34moffline_backbone.res3.3.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.3.conv1.weight[0m
[34moffline_backbone.res3.3.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.3.conv2.weight[0m
[34moffline_backbone.res3.3.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res3.3.conv3.weight[0m
[34moffline_backbone.res4.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.0.conv1.weight[0m
[34moffline_backbone.res4.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.0.conv2.weight[0m
[34moffline_backbone.res4.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.0.conv3.weight[0m
[34moffline_backbone.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.0.shortcut.weight[0m
[34moffline_backbone.res4.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.1.conv1.weight[0m
[34moffline_backbone.res4.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.1.conv2.weight[0m
[34moffline_backbone.res4.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.1.conv3.weight[0m
[34moffline_backbone.res4.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.2.conv1.weight[0m
[34moffline_backbone.res4.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.2.conv2.weight[0m
[34moffline_backbone.res4.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.2.conv3.weight[0m
[34moffline_backbone.res4.3.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.3.conv1.weight[0m
[34moffline_backbone.res4.3.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.3.conv2.weight[0m
[34moffline_backbone.res4.3.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.3.conv3.weight[0m
[34moffline_backbone.res4.4.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.4.conv1.weight[0m
[34moffline_backbone.res4.4.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.4.conv2.weight[0m
[34moffline_backbone.res4.4.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.4.conv3.weight[0m
[34moffline_backbone.res4.5.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.5.conv1.weight[0m
[34moffline_backbone.res4.5.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.5.conv2.weight[0m
[34moffline_backbone.res4.5.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.res4.5.conv3.weight[0m
[34moffline_backbone.stem.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34moffline_backbone.stem.conv1.weight[0m
[34moffline_proposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34moffline_proposal_generator.rpn_head.conv.{bias, weight}[0m
[34moffline_proposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_bg_score.weight[0m
[34mroi_heads.box_predictor.cls_score.weight[0m
[09/09 19:06:47] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mignore_others[0m
  [35moffline_backbone.bottom_up.res2.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res2.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res2.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res2.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res2.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res2.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res2.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res2.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res2.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res2.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res3.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.res3.3.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.3.conv1.weight[0m
  [35moffline_backbone.bottom_up.res3.3.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.3.conv2.weight[0m
  [35moffline_backbone.bottom_up.res3.3.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res3.3.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res4.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.3.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.3.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.3.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.3.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.3.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.3.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.4.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.4.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.4.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.4.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.4.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.4.conv3.weight[0m
  [35moffline_backbone.bottom_up.res4.5.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.5.conv1.weight[0m
  [35moffline_backbone.bottom_up.res4.5.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.5.conv2.weight[0m
  [35moffline_backbone.bottom_up.res4.5.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res4.5.conv3.weight[0m
  [35moffline_backbone.bottom_up.res5.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.conv1.weight[0m
  [35moffline_backbone.bottom_up.res5.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.conv2.weight[0m
  [35moffline_backbone.bottom_up.res5.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.conv3.weight[0m
  [35moffline_backbone.bottom_up.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.0.shortcut.weight[0m
  [35moffline_backbone.bottom_up.res5.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.1.conv1.weight[0m
  [35moffline_backbone.bottom_up.res5.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.1.conv2.weight[0m
  [35moffline_backbone.bottom_up.res5.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.1.conv3.weight[0m
  [35moffline_backbone.bottom_up.res5.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.2.conv1.weight[0m
  [35moffline_backbone.bottom_up.res5.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.2.conv2.weight[0m
  [35moffline_backbone.bottom_up.res5.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.res5.2.conv3.weight[0m
  [35moffline_backbone.bottom_up.stem.conv1.norm.{bias, running_mean, running_var, weight}[0m
  [35moffline_backbone.bottom_up.stem.conv1.weight[0m
  [35moffline_backbone.fpn_lateral2.{bias, weight}[0m
  [35moffline_backbone.fpn_lateral3.{bias, weight}[0m
  [35moffline_backbone.fpn_lateral4.{bias, weight}[0m
  [35moffline_backbone.fpn_lateral5.{bias, weight}[0m
  [35moffline_backbone.fpn_output2.{bias, weight}[0m
  [35moffline_backbone.fpn_output3.{bias, weight}[0m
  [35moffline_backbone.fpn_output4.{bias, weight}[0m
  [35moffline_backbone.fpn_output5.{bias, weight}[0m
[09/09 19:06:47] d2.data.datasets.coco INFO: Loaded 4836 images in COCO format from datasets/coco/annotations/ovd_ins_val2017_all.json
[09/09 19:06:48] d2.data.build INFO: Distribution of instances among all 65 categories:
[36m|  category  | #instances   |  category  | #instances   |   category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:------------:|:-------------|
|   person   | 10777        |  bicycle   | 314          |     car      | 1918         |
| motorcycle | 367          |  airplane  | 143          |     bus      | 283          |
|   train    | 190          |   truck    | 414          |     boat     | 424          |
|   bench    | 411          |    bird    | 427          |     cat      | 202          |
|    dog     | 218          |   horse    | 272          |    sheep     | 354          |
|    cow     | 372          |  elephant  | 252          |     bear     | 71           |
|   zebra    | 266          |  giraffe   | 232          |   backpack   | 371          |
|  umbrella  | 407          |  handbag   | 540          |     tie      | 252          |
|  suitcase  | 299          |  frisbee   | 115          |     skis     | 241          |
| snowboard  | 69           |    kite    | 327          |  skateboard  | 179          |
| surfboard  | 267          |   bottle   | 1013         |     cup      | 895          |
|    fork    | 215          |   knife    | 325          |    spoon     | 253          |
|    bowl    | 623          |   banana   | 370          |    apple     | 236          |
|  sandwich  | 177          |   orange   | 285          |   broccoli   | 312          |
|   carrot   | 365          |   pizza    | 284          |    donut     | 328          |
|    cake    | 310          |   chair    | 1771         |    couch     | 261          |
|    bed     | 163          |   toilet   | 179          |      tv      | 288          |
|   laptop   | 231          |   mouse    | 106          |    remote    | 283          |
|  keyboard  | 153          | microwave  | 55           |     oven     | 143          |
|  toaster   | 9            |    sink    | 225          | refrigerator | 126          |
|    book    | 1129         |   clock    | 267          |     vase     | 274          |
|  scissors  | 36           | toothbrush | 57           |              |              |
|   total    | 32721        |            |              |              |              |[0m
[09/09 19:06:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/09 19:06:48] d2.data.common INFO: Serializing 4836 elements to byte tensors and concatenating them all ...
[09/09 19:06:48] d2.data.common INFO: Serialized dataset takes 17.62 MiB
[09/09 19:06:48] d2.evaluation.evaluator INFO: Start inference on 4836 batches
